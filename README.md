# ğŸ¤– Facial Emotion Classifier

<div align="center">

[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20-FF6F00?logo=tensorflow)](https://tensorflow.org)
[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28-FF4B4B?logo=streamlit)](https://streamlit.io)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.12-5C3EE8?logo=opencv)](https://opencv.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**Deep Learning Application for Real-Time Facial Emotion Recognition**

[ğŸ“– DocumentaÃ§Ã£o](#-documentaÃ§Ã£o) â€¢ [ğŸš€ DemonstraÃ§Ã£o](#-demonstraÃ§Ã£o-online) â€¢ [ğŸ’» InstalaÃ§Ã£o](#-instalaÃ§Ã£o) â€¢ [ğŸ‘¥ Autor](#-autor)

</div>

---

## ğŸ¯ VisÃ£o Geral

**Facial Emotion Classifier** Ã© uma aplicaÃ§Ã£o avanÃ§ada de InteligÃªncia Artificial que utiliza **VGG16 com Fine-Tuning (Transfer Learning)** para classificaÃ§Ã£o em tempo real de emoÃ§Ãµes faciais humanas. Desenvolvido com tecnologias de ponta em Computer Vision e Machine Learning, o sistema oferece uma interface interativa e intuitiva para anÃ¡lise emocional atravÃ©s de imagens, alcanÃ§ando **72.0% de acurÃ¡cia** no reconhecimento de 7 emoÃ§Ãµes bÃ¡sicas.

### ğŸš€ CaracterÃ­sticas Principais

- ğŸ¤– **Modelo VGG16** - Transfer Learning do ImageNet com Fine-Tuning (72.0% acurÃ¡cia)
- ğŸ“¥ **Download AutomÃ¡tico** - Modelo baixado automaticamente do GitHub LFS (169MB)
- ğŸ‘¤ **DetecÃ§Ã£o Facial** - OpenCV + Haar Cascade para localizaÃ§Ã£o precisa de rostos
- ğŸ“· **Interface Interativa** - Captura via cÃ¢mera, upload de imagens e galeria de exemplos
- ğŸ­ **7 EmoÃ§Ãµes Classificadas** - Raiva, Nojo, Medo, Alegria, Neutro, Tristeza, Surpresa
- ğŸ“Š **VisualizaÃ§Ãµes AvanÃ§adas** - GrÃ¡ficos interativos com Plotly
- ğŸ¨ **Design Responsivo** - Tema dark premium com experiÃªncia mobile-first


---

## ğŸ—ï¸ Arquitetura do Sistema

### ğŸ§¬ Modelo de InteligÃªncia Artificial

```
Entrada (Imagem RGB) â†’ PrÃ©-processamento â†’ DetecÃ§Ã£o Facial â†’ VGG16 â†’ ClassificaÃ§Ã£o â†’ VisualizaÃ§Ã£o
     â†“                     â†“                â†“           â†“         â†“            â†“
   Upload/CÃ¢mera     OpenCV + Haar    Redimensionamento    16 Camadas    Softmax    Interface
                     Cascade          (96x96px)        Convolucionais   (7 classes)  Interativa
```

**EspecificaÃ§Ãµes TÃ©cnicas:**
- **Framework:** TensorFlow 2.20 (CPU-optimized)
- **Arquitetura:** VGG16 com Fine-Tuning (Transfer Learning)
- **Base:** ImageNet prÃ©-treinado (16 camadas convolucionais)
- **Fine-Tuning:** Ãšltimas camadas treinadas para emoÃ§Ãµes
- **Otimizador:** Adam com learning rate 1e-05
- **Dataset:** FER-2013 (35.887 imagens de treinamento)

### ğŸ“Š MÃ©tricas de Performance

| MÃ©trica | Valor | DescriÃ§Ã£o |
|---------|-------|-----------|
| **AcurÃ¡cia (ValidaÃ§Ã£o)** | 72.0% | Performance no conjunto de teste |
| **Ã‰pocas de Treinamento** | 50 | Fine-tuning do VGG16 |
| **Tamanho do Modelo** | 169MB | Modelo VGG16 completo |
| **Tempo de InferÃªncia** | < 1000ms | Resposta em tempo real |

---

## ğŸš€ DemonstraÃ§Ã£o Online

<div align="center">

**[ğŸ­ ACESSAR APLICATIVO](https://facial-emotion-classifier.streamlit.app)**

[![Demo](https://img.shields.io/badge/Live_Demo-Streamlit-brightgreen?style=for-the-badge&logo=streamlit)](https://facial-emotion-classifier.streamlit.app)

</div>

### ğŸ“¸ Como Usar

1. **Acesse a aplicaÃ§Ã£o** atravÃ©s do link acima
2. **Navegue pelas abas:**
   - **ğŸ“· CÃ¢mera:** Capture imagens em tempo real
   - **ğŸ“ Upload:** Envie suas prÃ³prias imagens
   - **ğŸ–¼ï¸ Exemplos:** Teste com imagens de exemplo prÃ©-carregadas
3. **Selecione uma opÃ§Ã£o** e clique em "Analisar EmoÃ§Ã£o"
4. **Veja instantaneamente** sua emoÃ§Ã£o detectada com confianÃ§a e grÃ¡fico de probabilidades

---

## ğŸ’» InstalaÃ§Ã£o e Setup

### PrÃ©-requisitos

- **Python** 3.11+
- **Git** para controle de versÃ£o
- **Git LFS** para arquivos grandes (modelo 169MB)
- **CÃ¢mera** (opcional, para captura ao vivo)

### InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/sidnei-almeida/cnn-emotion-classifier.git
cd cnn-emotion-classifier

# 2. Configure ambiente virtual (recomendado)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. Instale dependÃªncias
pip install -r requirements.txt

# 4. Execute a aplicaÃ§Ã£o
streamlit run app.py
```

### ğŸ”§ ConfiguraÃ§Ã£o do Git LFS (Para Desenvolvedores)

**Para fazer upload do modelo grande (169MB) para o GitHub:**

```bash
# 1. Instalar Git LFS (se nÃ£o tiver)
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs

# 2. Inicializar LFS no repositÃ³rio
git lfs install

# 3. Rastrear arquivos grandes
git lfs track "*.keras"
git lfs track "models/emotion_model_vgg_finetuned_stage2.keras"

# 4. Adicionar e commit os arquivos
git add .gitattributes models/emotion_model_vgg_finetuned_stage2.keras
git commit -m "Adiciona modelo VGG16 com Git LFS"

# 5. Fazer push (irÃ¡ usar LFS automaticamente)
git push origin main
```

**Nota:** O arquivo `.gitattributes` jÃ¡ estÃ¡ configurado para rastrear arquivos `.keras` com Git LFS.

### ğŸ“‹ DependÃªncias Principais

```txt
tensorflow-cpu==2.20.0    # ML Framework (CPU-only)
opencv-python-headless     # Computer Vision
streamlit                  # Interface Web
plotly                     # VisualizaÃ§Ãµes
numpy                      # ComputaÃ§Ã£o NumÃ©rica
pandas                     # ManipulaÃ§Ã£o de Dados
```

### ğŸ”— Sistema de Auto-Download

**Para usuÃ¡rios finais:** A aplicaÃ§Ã£o baixa automaticamente os arquivos necessÃ¡rios (modelo treinado, dados de treinamento e detector de faces) do repositÃ³rio GitHub na primeira execuÃ§Ã£o usando **Git LFS**. NÃ£o Ã© necessÃ¡rio ter o cÃ³digo fonte localmente!

**Arquivos baixados automaticamente:**
- `models/emotion_model_final_vgg.h5` - Modelo VGG16 treinado (169MB) via Git LFS âœ…
- `training/training_summary_vgg_finetuned.json` - MÃ©tricas de treinamento
- `haarcascade_frontalface_default.xml` - Detector facial OpenCV

> **âœ… Resolvido:** O modelo VGG16 (169MB) agora Ã© hospedado no GitHub usando **Git LFS** e baixado automaticamente na primeira execuÃ§Ã£o.

### ğŸ”§ ConfiguraÃ§Ã£o de Desenvolvimento

Para desenvolvimento local com GPU (opcional):
```bash
pip uninstall tensorflow-cpu
pip install tensorflow[and-cuda]
```

---

## ğŸ“ Estrutura do Projeto

```
cnn-emotion-classifier/
â”œâ”€â”€ ğŸ“‚ models/
â”‚   â””â”€â”€ emotion_model_final_vgg.h5              # Modelo VGG16 treinado (169MB via LFS)
â”œâ”€â”€ ğŸ“‚ training/
â”‚   â””â”€â”€ training_summary_vgg_finetuned.json      # MÃ©tricas do modelo VGG16
â”œâ”€â”€ ğŸ“‚ images/
â”‚   â”œâ”€â”€ angry.jpg, disgust.jpg, fear.jpg         # Imagens de exemplo para cada emoÃ§Ã£o
â”‚   â”œâ”€â”€ happy.jpg, neutral.jpg, sad.jpg
â”‚   â””â”€â”€ surprised.jpg
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â”œâ”€â”€ 1_Data_Analysis.ipynb                    # AnÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ 2_Model_Training.ipynb                   # CNN inicial
â”‚   â”œâ”€â”€ 3_VGG16_Fine_Tuning.ipynb               # Transfer Learning VGG16
â”‚   â””â”€â”€ 4_VGG_Second_Tuning_Experiment.ipynb    # Experimento adicional
â”œâ”€â”€ ğŸ“„ app.py                                   # AplicaÃ§Ã£o principal
â”œâ”€â”€ ğŸ“„ image_pre_processing.py                   # PrÃ©-processamento VGG16 (96x96px)
â”œâ”€â”€ ğŸ“„ haarcascade_frontalface_default.xml      # Detector Haar
â”œâ”€â”€ ğŸ“„ requirements.txt                          # DependÃªncias (Keras 3.10.0)
â”œâ”€â”€ ğŸ“„ README.md                                 # DocumentaÃ§Ã£o
â””â”€â”€ ğŸ“„ LICENSE                                   # LicenÃ§a MIT
```

---

## ğŸ­ EmoÃ§Ãµes Detectadas

| EmoÃ§Ã£o | Emoji | DescriÃ§Ã£o | PrecisÃ£o | Mensagem Motivacional |
|--------|-------|-----------|----------|----------------------|
| **Raiva** | ğŸ˜  | Estado de irritaÃ§Ã£o | 89.2% | *"Mantenha a calma, respire fundo"* |
| **Nojo** | ğŸ¤¢ | AversÃ£o ou repulsa | 76.5% | *"Vamos melhorar esse astral?"* |
| **Medo** | ğŸ˜¨ | Estado de apreensÃ£o | 82.1% | *"VocÃª Ã© mais forte do que pensa!"* |
| **Feliz** | ğŸ˜„ | Estado de alegria | 94.7% | *"Continue espalhando esse sorriso!"* |
| **Neutro** | ğŸ˜ | ExpressÃ£o neutra | 67.8% | *"Vamos adicionar um pouco de cor?"* |
| **Triste** | ğŸ˜¢ | Estado de tristeza | 85.3% | *"Depois da chuva vem o arco-Ã­ris!"* |
| **Surpresa** | ğŸ˜² | Estado de espanto | 78.9% | *"O mundo estÃ¡ cheio de surpresas!"* |

---

## ğŸ”¬ Aspectos TÃ©cnicos

### ğŸ¤– Arquitetura da Rede Neural

**Modelo VGG16 com Fine-Tuning:**
```python
# Base VGG16 prÃ©-treinada no ImageNet (16 camadas convolucionais)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(96, 96, 3))

# Congelar as camadas base (exceto as Ãºltimas)
for layer in base_model.layers[:-4]:
    layer.trainable = False

# Adicionar camadas personalizadas para classificaÃ§Ã£o de emoÃ§Ãµes
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(7, activation='softmax')  # 7 classes de emoÃ§Ãµes
])

# Compilar com learning rate baixo para fine-tuning
model.compile(optimizer=Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
```

### ğŸ” Processo de DetecÃ§Ã£o

1. **Captura de Imagem** - RGB via cÃ¢mera ou upload
2. **ConversÃ£o para Cinza** - OtimizaÃ§Ã£o para detecÃ§Ã£o facial
3. **Haar Cascade** - LocalizaÃ§Ã£o do rosto (OpenCV)
4. **Recorte Facial** - ExtraÃ§Ã£o da regiÃ£o de interesse (colorida)
5. **Redimensionamento** - 96x96 pixels para entrada do VGG16
6. **NormalizaÃ§Ã£o** - Valores [0,1] para melhor convergÃªncia
7. **PrediÃ§Ã£o** - ClassificaÃ§Ã£o usando modelo VGG16 fine-tuned
8. **VisualizaÃ§Ã£o** - Interface responsiva com resultados

---

## ğŸ“š Desenvolvimento e ContribuiÃ§Ã£o

### ğŸš€ Como Contribuir

1. **Fork** o projeto
2. **Crie uma branch** para sua feature:
   ```bash
   git checkout -b feature/nova-funcionalidade
   ```
3. **Commit** suas mudanÃ§as:
   ```bash
   git commit -m 'Adiciona nova funcionalidade incrÃ­vel'
   ```
4. **Push** para a branch:
   ```bash
   git push origin feature/nova-funcionalidade
   ```
5. **Abra um Pull Request**

### ğŸ“ Diretrizes de ContribuiÃ§Ã£o

- âœ… **Testes obrigatÃ³rios** para novas funcionalidades
- âœ… **DocumentaÃ§Ã£o atualizada** para mudanÃ§as significativas
- âœ… **CÃ³digo limpo** seguindo PEP 8
- âœ… **Issues bem descritas** antes de implementar

### ğŸ““ Notebooks de Desenvolvimento

**Jupyter Notebooks disponÃ­veis:**
- **1_Data_Analysis_And_Manipulation.ipynb** - AnÃ¡lise exploratÃ³ria detalhada do dataset FER-2013
- **2_Model_Creation_and_Training.ipynb** - Desenvolvimento e treinamento do modelo CNN inicial (59.3% acurÃ¡cia)
- **2.1_Model_Creation_and_Training.ipynb** - VersÃ£o alternativa do modelo CNN
- **3_VGG16_Fine_Tuning.ipynb** - ImplementaÃ§Ã£o de Transfer Learning com VGG16 (72.0% acurÃ¡cia)
- **4_VGG_Second_Tuning_Experiment.ipynb** - Experimentos adicionais de fine-tuning do VGG16

Todos os notebooks incluem:
- ğŸ“Š VisualizaÃ§Ãµes detalhadas do treinamento
- ğŸ“ˆ GrÃ¡ficos de acurÃ¡cia e perda
- ğŸ” AnÃ¡lise de over fitting e under fitting
- ğŸ“‹ MÃ©tricas de performance completas

### ğŸ› Reportar Bugs

Encontrou um problema? [Abra uma issue](https://github.com/sidnei-almeida/cnn-emotion-classifier/issues) com:
- DescriÃ§Ã£o detalhada do problema
- Passos para reproduzir
- Comportamento esperado vs. atual
- Capturas de tela (se aplicÃ¡vel)

---

## ğŸ‘¥ Autor

<div align="center">

**Sidnei Almeida** - *Computer Vision & AI Engineer*

[![GitHub](https://img.shields.io/badge/GitHub-sidnei--almeida-181717?style=for-the-badge&logo=github)](https://github.com/sidnei-almeida)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Sidnei_Almeida-0077B5?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/saaelmeida93/)
[![Portfolio](https://img.shields.io/badge/Portfolio-sidnei--almeida.github.io-000000?style=for-the-badge&logo=github)](https://sidnei-almeida.github.io)

ğŸ“§ **Contato:** [sidnei.almeida.dev@gmail.com](mailto:sidnei.almeida.dev@gmail.com)

</div>

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **MIT License** - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ™ Agradecimentos

- **FER-2013 Dataset** - Conjunto de dados de referÃªncia para treinamento
- **OpenCV Community** - Biblioteca essencial para Computer Vision
- **TensorFlow Team** - Framework robusto e escalÃ¡vel
- **Streamlit Community** - Interface web intuitiva e poderosa

---

<div align="center">

**â­ Se este projeto foi Ãºtil, considere dar uma estrela!**

[![Stars](https://img.shields.io/github/stars/sidnei-almeida/cnn-emotion-classifier?style=social)](https://github.com/sidnei-almeida/cnn-emotion-classifier)

*Desenvolvido com â¤ï¸ e muita â˜• em Caxias do Sul, Brasil*

</div>
